from multiprocessing import Process, Manager
from flashtext import KeywordProcessor
import pickle
import numpy as np
import os
from tqdm import tqdm

def get_opcode_unigrams(kp, file, op_proc):
    f = open(file, 'rb')
    # name = file.split('.')[0]
    data = str(f.read())
    f.close()
    text = kp.extract_keywords(data)
    opcode_counts = dict(zip(op_proc,[0]*len(op_proc)))
    for w in text: 
        try: opcode_counts[w]+=1
        except: pass
    
    return opcode_counts

def process(batch, common_dict, kp, op_proc):
    
    root='D:\\Downloads\\'+batch
    files=os.listdir(root)
    
    for file in tqdm(files, desc='Fetching opcodes in folder {}'.format(batch)):
        common_dict[file]=get_opcode_unigrams(kp, root+'\\'+file, op_proc)
    
    print(f'folder {batch} completed')

def main():
    
    f = open('./key_words.txt','r') 
    op = f.read().split('\n')
    
    op.pop(-1)
    op_proc=[]
    for kw in op:
        op_proc.append(kw.rstrip('\t'))
        
    f.close()
    
    for i in range(141, len(op_proc)):
        op_proc.pop(141)
        
    kp = KeywordProcessor() 
    for w in op_proc: kp.add_keyword(w.lower())
    
    folders=['first_asm', 'second_asm', 'third_asm', 'fourth_asm', 'fifth_asm']
    
    m=Manager()
    common_dict=m.dict()
    
    processes=[]
    for folder in folders:
        processes.append(Process(target=process, args=(folder, common_dict, kp, op_proc)))
    
    for p in processes:
        p.start()
    
    for p in processes:
        p.join()
    
    with open('opcode_columns.pickle', 'wb') as f:
        pickle.dump(op_proc, f)
    
    vec=np.ndarray(shape=(len(common_dict.keys()), len(op_proc)), dtype=float)
    for i, file in enumerate(common_dict.keys()):
        for j, col in enumerate(common_dict[file].keys()):
            vec[i, j]=common_dict[file][col]
    
    np.save('./opcode_features.npy', vec)
    
    with open('./opcode_file_ids.pickle', 'wb') as f:
        pickle.dump(common_dict.keys(), f)

if __name__=='__main__':
    main()
